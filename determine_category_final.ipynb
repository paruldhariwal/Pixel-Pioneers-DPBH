{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86e2b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|███████████████████████████| 133/133 [05:43<00:00,  2.58s/batches]\n",
      "Epoch 2: 100%|███████████████████████████| 133/133 [16:45<00:00,  7.56s/batches]\n",
      "Epoch 3: 100%|███████████████████████████| 133/133 [05:31<00:00,  2.50s/batches]\n",
      "Evaluating: 100%|██████████████████████████| 38/38 [00:13<00:00,  2.78batches/s]\n",
      "Evaluating on Validation Set: 100%|████████| 19/19 [00:06<00:00,  2.94batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9735368437541221\n",
      "Recall: 0.9736842105263158\n",
      "F1 Score: 0.9732862688184764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "selected_classification = 'Pattern Category'\n",
    "df = pd.read_csv('dark_patterns.csv')\n",
    "df = df[pd.notnull(df['Pattern String'])]\n",
    "col = ['Pattern String', selected_classification]\n",
    "df = df[col]\n",
    "\n",
    "# Convert string labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_labels'] = label_encoder.fit_transform(df[selected_classification])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# train_df, temp_df = train_test_split(df, test_size=0.5, random_state=42)\n",
    "# test_df, val_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "num_labels = len(df['encoded_labels'].unique())  # Number of unique classes\n",
    "new_model1 = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "new_model = new_model1\n",
    "# Tokenize and encode the training data\n",
    "train_encodings = tokenizer(list(train_df['Pattern String']), truncation=True, padding=True, return_tensors='pt')\n",
    "train_labels = torch.tensor(train_df['encoded_labels'].tolist())\n",
    "\n",
    "# Tokenize and encode the testing data\n",
    "test_encodings = tokenizer(list(test_df['Pattern String']), truncation=True, padding=True, return_tensors='pt')\n",
    "test_labels = torch.tensor(test_df['encoded_labels'].tolist())\n",
    "\n",
    "# Tokenize and encode the validation data\n",
    "val_encodings = tokenizer(list(val_df['Pattern String']), truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Create a DataLoader for validation\n",
    "val_dataset = TensorDataset(val_encodings['input_ids'], val_encodings['attention_mask'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "# Create a DataLoader for training and testing\n",
    "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Set up optimizer and loss function\n",
    "optimizer = AdamW(new_model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "new_model.train()\n",
    "for epoch in range(3):  # Adjust the number of epochs as needed\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}', unit='batches'):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = new_model(input_ids=batch[0], attention_mask=batch[1], labels=batch[2])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "new_model.eval()\n",
    "y_pred_proba = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc='Evaluating', unit='batches'):\n",
    "        outputs = new_model(input_ids=batch[0], attention_mask=batch[1])\n",
    "        y_pred_proba.extend(torch.softmax(outputs.logits, dim=1).tolist())\n",
    "\n",
    "y_pred_labels = [torch.argmax(torch.tensor(proba)).item() for proba in y_pred_proba]\n",
    "\n",
    "\n",
    "y_pred_proba_val = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader, desc='Evaluating on Validation Set', unit='batches'):\n",
    "        outputs = new_model(input_ids=batch[0], attention_mask=batch[1])\n",
    "        y_pred_proba_val.extend(torch.softmax(outputs.logits, dim=1).tolist())\n",
    "        \n",
    "y_pred_labels_val = [torch.argmax(torch.tensor(proba)).item() for proba in y_pred_proba_val]\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(test_labels.tolist(), y_pred_labels)\n",
    "precision = precision_score(test_labels.tolist(), y_pred_labels, average='weighted')\n",
    "recall = recall_score(test_labels.tolist(), y_pred_labels, average='weighted')\n",
    "f1 = f1_score(test_labels.tolist(), y_pred_labels, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76147ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_labels_val = [torch.argmax(torch.tensor(proba)).item() for proba in y_pred_proba_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41760795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 6, 5, 3, 3, 6, 6, 3, 5, 1, 3, 3, 3, 3, 3, 5, 3, 5, 3, 3, 3, 1, 3, 3, 6, 5, 5, 3, 5, 3, 5, 5, 6, 5, 3, 6, 6, 3, 3, 3, 6, 3, 3, 3, 5, 6, 3, 3, 3, 3, 5, 3, 3, 6, 6, 6, 3, 2, 3, 3, 3, 3, 3, 1, 3, 5, 3, 3, 3, 6, 3, 3, 1, 1, 5, 6, 3, 3, 3, 6, 3, 1, 1, 3, 5, 1, 3, 3, 3, 1, 1, 3, 3, 3, 3, 1, 5, 3, 3, 5, 5, 3, 3, 5, 3, 5, 3, 3, 1, 1, 5, 5, 6, 1, 3, 3, 6, 3, 3, 3, 3, 3, 5, 3, 5, 6, 1, 3, 3, 6, 1, 1, 3, 1, 1, 3, 5, 1, 3, 3, 3, 2, 3, 3, 3, 3, 1, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a900689c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern String</th>\n",
       "      <th>Pattern Category</th>\n",
       "      <th>encoded_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>Availability: Only 4 Left!</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>Only 498 left</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>02 DAYS :23 HOURS :00 MINS :54 SECS</td>\n",
       "      <td>Urgency</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>232 people are viewing this offer!</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>3 Left!</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Only 2 units left in stock</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>In Stock only 3 left</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>No thanks, I don't want to save up to 75%</td>\n",
       "      <td>Misdirection</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>166 people have added this item to cart</td>\n",
       "      <td>Social Proof</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>Only 5 left in stock</td>\n",
       "      <td>Scarcity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Pattern String Pattern Category  \\\n",
       "1535                 Availability: Only 4 Left!         Scarcity   \n",
       "1264                              Only 498 left         Scarcity   \n",
       "593         02 DAYS :23 HOURS :00 MINS :54 SECS          Urgency   \n",
       "308          232 people are viewing this offer!     Social Proof   \n",
       "1637                                    3 Left!         Scarcity   \n",
       "...                                         ...              ...   \n",
       "1131                 Only 2 units left in stock         Scarcity   \n",
       "1616                       In Stock only 3 left         Scarcity   \n",
       "481   No thanks, I don't want to save up to 75%     Misdirection   \n",
       "54      166 people have added this item to cart     Social Proof   \n",
       "1244                       Only 5 left in stock         Scarcity   \n",
       "\n",
       "      encoded_labels  \n",
       "1535               3  \n",
       "1264               3  \n",
       "593                6  \n",
       "308                5  \n",
       "1637               3  \n",
       "...              ...  \n",
       "1131               3  \n",
       "1616               3  \n",
       "481                1  \n",
       "54                 5  \n",
       "1244               3  \n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "baf9a378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_val: 0.9933333333333333\n",
      "Precision_val: 0.9936842105263158\n",
      "Recall_val: 0.9933333333333333\n",
      "F1 Score_val: 0.9934032214032215\n"
     ]
    }
   ],
   "source": [
    "val_labels = torch.tensor(val_df['encoded_labels'].tolist())\n",
    "\n",
    "accuracy_val = accuracy_score(val_labels.tolist(), y_pred_labels_val)\n",
    "precision_val = precision_score(val_labels.tolist(), y_pred_labels_val, average='weighted')\n",
    "recall_val = recall_score(val_labels.tolist(), y_pred_labels_val, average='weighted')\n",
    "f1_val = f1_score(val_labels.tolist(), y_pred_labels_val, average='weighted')\n",
    "print(f\"Accuracy_val: {accuracy_val}\")\n",
    "print(f\"Precision_val: {precision_val}\")\n",
    "print(f\"Recall_val: {recall_val}\")\n",
    "print(f\"F1 Score_val: {f1_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c27f4e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['determine_category_label_encoder.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model_state_dict = new_model.state_dict()\n",
    "joblib.dump(model_state_dict, 'determine_category_bert_model.joblib')\n",
    "#save the label encoder as well\n",
    "joblib.dump(label_encoder, 'determine_category_label_encoder.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7423e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
